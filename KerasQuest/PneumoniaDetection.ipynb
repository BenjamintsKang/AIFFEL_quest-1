{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyOj41n7NJnUC0MnpZbFXhqr",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/udoli3/AIFFEL_quest/blob/main/KerasQuest/PneumoniaDetection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Main Quest CR8"
      ],
      "metadata": {
        "id": "NILVliaY-vCH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#폐렴 진단 모델"
      ],
      "metadata": {
        "id": "osgakJoN-png"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##0. 설계\n",
        "\n",
        "아이펠 코어 과정 CV 모듈 학습의 일환으로 아래 모델을 구성해본다.\n",
        "\n",
        "1. 데이터 살펴보기\n",
        "2. 데이터 전처리\n",
        "3. 모델링, 하이퍼파라미터 튜닝\n",
        "4. 결과\n",
        "  * 요약\n",
        "  * 회고"
      ],
      "metadata": {
        "id": "nyywT2-Lo8UC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##1. 데이터 살펴보기"
      ],
      "metadata": {
        "id": "RDkAyQtDq6i4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###1. 라이브러리 준비"
      ],
      "metadata": {
        "id": "7FW5KEx7x3cZ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-6JRuuGqxuQE"
      },
      "outputs": [],
      "source": [
        "import os, re\n",
        "import random, math\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.utils import plot_model\n",
        "import warnings\n",
        "warnings.filterwarnings(action='ignore')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###2. 필요한 변수들 생성(상수들)"
      ],
      "metadata": {
        "id": "ckwQZITKx5wD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 데이터 로드할 때 빠르게 로드할 수 있도록하는 설정 변수\n",
        "AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
        "# X-RAY 이미지 사이즈 변수\n",
        "IMAGE_SIZE = [180, 180]\n",
        "\n",
        "# 데이터 경로 변수\n",
        "ROOT_PATH = os.path.join(os.getenv('HOME'), 'aiffel')\n",
        "TRAIN_PATH = ROOT_PATH + '/chest_xray/data/train/*/*' # *은 모든 디렉토리와 파일을 의미합니다.\n",
        "VAL_PATH = ROOT_PATH + '/chest_xray/data/val/*/*'\n",
        "TEST_PATH = ROOT_PATH + '/chest_xray/data/test/*/*'\n",
        "\n",
        "# 프로젝트를 진행할 때 아래 두 변수를 변경해보세요\n",
        "BATCH_SIZE = 16\n",
        "EPOCHS = 10\n",
        "\n",
        "print(ROOT_PATH)"
      ],
      "metadata": {
        "id": "EU5B7GGQywIB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###3. 데이터 가져오기 및 구분하기"
      ],
      "metadata": {
        "id": "0d-Z55W8x-c1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "데이터 구성\n",
        "* train\n",
        "* val(validation)\n",
        "* test"
      ],
      "metadata": {
        "id": "BSzTe4Gcy0zP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "####3.1 확인하기 (훈련, 검증 세트 균형)"
      ],
      "metadata": {
        "id": "lBgLzbqTvUNA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "균형 확인"
      ],
      "metadata": {
        "id": "ezMTyDnuuncy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_filenames = tf.io.gfile.glob(TRAIN_PATH)\n",
        "test_filenames = tf.io.gfile.glob(TEST_PATH)\n",
        "val_filenames = tf.io.gfile.glob(VAL_PATH)\n",
        "\n",
        "print(len(train_filenames))\n",
        "print(len(test_filenames))\n",
        "print(len(val_filenames))"
      ],
      "metadata": {
        "id": "iaRx61J4y0Gc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* val_filenames 가 지나치게 작다."
      ],
      "metadata": {
        "id": "gN9_nQSbzGkQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "####3.2 분할하기 (훈련, 검증 세트 구분)"
      ],
      "metadata": {
        "id": "pxaEe73lvicj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "∴ train : val를 80:20으로 분할하기"
      ],
      "metadata": {
        "id": "Jjl6APAnzDJw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# train 데이터와 validation 데이터를 모두 filenames에 담습니다\n",
        "filenames = tf.io.gfile.glob(TRAIN_PATH)\n",
        "filenames.extend(tf.io.gfile.glob(VAL_PATH))\n",
        "\n",
        "# 모아진 filenames를 8:2로 나눕니다\n",
        "train_size = math.floor(len(filenames)*0.8)\n",
        "# 실험결과 재현 용이하도록 시드 먼저 주고 섞기(shuffle)\n",
        "random.seed(8)\n",
        "random.shuffle(filenames)\n",
        "# 순서 정해 섞었으면 자르기\n",
        "train_filenames = filenames[:train_size]\n",
        "val_filenames = filenames[train_size:]"
      ],
      "metadata": {
        "id": "oTdv_IpazC1L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "확인"
      ],
      "metadata": {
        "id": "UeS0armEvHdp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(train_filenames))\n",
        "print(len(val_filenames))"
      ],
      "metadata": {
        "id": "3Oa7tRwXvIH2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* 훈련세트 이미지 수:\n",
        "* 검증세트 이미지 수:"
      ],
      "metadata": {
        "id": "V2u5iyE5x0Eq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "####3.3 확인하기 (라벨 균형)"
      ],
      "metadata": {
        "id": "cBIBSKvVwIT3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "데이터 얼마나 불균형인가?\n",
        "\n",
        "각 이미지 수 확인하기 (경로 이름에 명시되어 있는 사실 활용하기)"
      ],
      "metadata": {
        "id": "2g97r-NN1Rqr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'Normal image path\\n{filenames[0]}')\n",
        "print(f'Pneumonia image path\\n{filenames[2000]}')"
      ],
      "metadata": {
        "id": "qb-N5hbG1RNw",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 158
        },
        "outputId": "12828b65-bda4-43d1-e8fd-b4467eed3be9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'filenames' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-52d15977c804>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'Normal image path\\n{filenames[0]}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'Pneumonia image path\\n{filenames[2000]}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'filenames' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "COUNT_NORMAL = len([filename for filename in train_filenames if \"NORMAL\" in filename])\n",
        "print(f\"Normal images count in training set: {COUNT_NORMAL}\")\n",
        "\n",
        "\n",
        "COUNT_PNEUMONIA = len([filename for filename in train_filenames if \"PNEUMONIA\" in filename])\n",
        "print(f\"Pneumonia images count in training set: {COUNT_PNEUMONIA}\")"
      ],
      "metadata": {
        "id": "unHd5rEZ1eo5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* 폐렴 음성 이미지 수: 1071\n",
        "* 폐럼 양성 이미지 수: 3114"
      ],
      "metadata": {
        "id": "tpcAp_oMxODC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#####mini-batch 활용 사전 준비"
      ],
      "metadata": {
        "id": "trQQgWR-1peX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "######tf.data 인스턴스 만들기"
      ],
      "metadata": {
        "id": "d8BxMZLR1vqh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_list_ds = tf.data.Dataset.from_tensor_slices(train_filenames)\n",
        "val_list_ds = tf.data.Dataset.from_tensor_slices(val_filenames)\n",
        "\n",
        "# for f in train_list_ds.take(5):\n",
        "    # print(f.numpy())"
      ],
      "metadata": {
        "id": "xtwUPVz71ovw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "######tf.data 인스턴스를 활용한 훈련세트, 검증세트 각각 이미지 개수 확인"
      ],
      "metadata": {
        "id": "JFA7M54s11qV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "TRAIN_IMG_COUNT = tf.data.experimental.cardinality(train_list_ds).numpy()\n",
        "print(f\"Training images count: {TRAIN_IMG_COUNT}\")\n",
        "\n",
        "VAL_IMG_COUNT = tf.data.experimental.cardinality(val_list_ds).numpy()\n",
        "print(f\"Validating images count: {VAL_IMG_COUNT}\")"
      ],
      "metadata": {
        "id": "qoMQ28Ix16TO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##2. 데이터 전처리"
      ],
      "metadata": {
        "id": "KUe7jAAFrWRJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###1. 라벨링"
      ],
      "metadata": {
        "id": "Cd3m9uGP1-QG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* 이미지 라벨 생성하기\n",
        "* 이미지 인덱스와 라벨 매칭시켜주기 (+이미지 크기 조정)"
      ],
      "metadata": {
        "id": "BjRGP1iTyaVa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "####라벨 데이터 만들어주기"
      ],
      "metadata": {
        "id": "Gy6DH2sU1-7k"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "라벨 데이터 만들어주는 함수 생성\n",
        "* 파일 경로의 끝에서 두번째 부분을 확인하면 양성과 음성을 구분 가능했다."
      ],
      "metadata": {
        "id": "8MH3JM6j1_-z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_label(file_path):\n",
        "    # path 를 구성 요소 단위로 리스트화\n",
        "    parts = tf.strings.split(file_path, os.path.sep)\n",
        "    # 끝에서 두 번째 부분 (즉 [-2]인덱스) == 경로에서 클래스를 나타내는 부분\n",
        "    return parts[-2] == \"PNEUMONIA\"   # 폐렴이면 양성(True), 노말이면 음성(False)"
      ],
      "metadata": {
        "id": "zGAiXx5x2BhC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###2. 이미지 사이즈 조정하기"
      ],
      "metadata": {
        "id": "m9nue9BS2GtO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* 원본 이미지는 0 ~ 255 값을 가지므로 (모델에 주입 가능하도록) 0 ~ 1 사이의 정수값을 가지도록 스케일링"
      ],
      "metadata": {
        "id": "m3_mHpYB0B0r"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "함수로 처리"
      ],
      "metadata": {
        "id": "qwQxR0A12sw8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def decode_img(img):\n",
        "    img = tf.image.decode_jpeg(img, channels=3) # 이미지를 uint8 tensor로 수정\n",
        "    img = tf.image.convert_image_dtype(img, tf.float32) # float32 타입으로 수정\n",
        "    img = tf.image.resize(img, IMAGE_SIZE) # 이미지 사이즈를 IMAGE_SIZE로 수정\n",
        "    return img"
      ],
      "metadata": {
        "id": "YQZ44RMr2NHZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###3. 이미지, 라벨 확인 (경로 입력하여 확인)"
      ],
      "metadata": {
        "id": "5hg3K-252jlK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* 이미지 파일의 경로 입력 --> 이미지와 라벨 읽어오기\n"
      ],
      "metadata": {
        "id": "EE6YKNov1FSd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "함수로 처리"
      ],
      "metadata": {
        "id": "XhNWrgCy2tkf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def process_path(file_path):\n",
        "    label = get_label(file_path) # 라벨 검출\n",
        "    img = tf.io.read_file(file_path) # 이미지 읽기\n",
        "    img = decode_img(img) # 이미지를 알맞은 형식으로 수정\n",
        "    return img, label"
      ],
      "metadata": {
        "id": "B6D87NmQ2Pe8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "####병렬 처리 적용 (훈련, 검증 세트)\n",
        "* map 함수로 데이터 처리 효율 개선"
      ],
      "metadata": {
        "id": "-huEyx1i25Gy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# process_path 함수를 train_list_ds 훈련세트 데이터셋의 각 요소에 적용하되, 병렬 처리하며 스레드 개수는 최적으로 자동 결정\n",
        "train_ds = train_list_ds.map(process_path, num_parallel_calls=AUTOTUNE)\n",
        "# val_list_ds 검증세트에도 적용\n",
        "val_ds = val_list_ds.map(process_path, num_parallel_calls=AUTOTUNE)"
      ],
      "metadata": {
        "id": "1Zk1q6ir26E5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "처리 확인해보자"
      ],
      "metadata": {
        "id": "Wou1A5nA2_dl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for image, label in train_ds.take(1):\n",
        "    print(\"Image shape: \", image.numpy().shape)\n",
        "    print(\"Label: \", label.numpy())"
      ],
      "metadata": {
        "id": "2h9nd_r43B4o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "####병렬 처리 적용 (테스트세트)\n",
        "\n"
      ],
      "metadata": {
        "id": "2iAv6vtT3FzS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 테스트세트도 tf.data 인스턴스 만들기 (mini-batch 활용 준비)\n",
        "test_list_ds = tf.data.Dataset.list_files(TEST_PATH)\n",
        "# tf.data 인스턴스를 활용한 테스트세트 이미지 개수 확인\n",
        "TEST_IMAGE_COUNT = tf.data.experimental.cardinality(test_list_ds).numpy()\n",
        "# 병렬처리 적용\n",
        "test_ds = test_list_ds.map(process_path, num_parallel_calls=AUTOTUNE)\n",
        "test_ds = test_ds.batch(BATCH_SIZE)\n",
        "\n",
        "print(TEST_IMAGE_COUNT)"
      ],
      "metadata": {
        "id": "Ix4zr0Mp3FVF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###4. 추가 처리 (데이터 셔플링, 반복하여 증강, 배치사이즈 조정, 데이터 사전 로딩)"
      ],
      "metadata": {
        "id": "lZPkXRJS4OJT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* 편향된 학습 방지 (무작위로 섞어서 데이터가 균일하게 사용되도록)\n",
        "* 데이터셋 효과적으로 늘리기 (복사하지 않고 반복 사용)\n",
        "* 배치 사이즈 조정해서 데이터 효율적으로 처리하기\n",
        "  * 너무 크면 오히려 성능 저하\n",
        "* 데이터 미리 로드해서 학습 속도 올리기\n",
        "  * 데이터셋 특성에 따라 적용해야함"
      ],
      "metadata": {
        "id": "hNZh1f0a3twG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "함수로 처리"
      ],
      "metadata": {
        "id": "dAOegX974sVK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def prepare_for_training(ds, shuffle_buffer_size=1000):\n",
        "    ds = ds.shuffle(buffer_size=shuffle_buffer_size)\n",
        "    ds = ds.repeat()\n",
        "    ds = ds.batch(BATCH_SIZE)\n",
        "    ds = ds.prefetch(buffer_size=AUTOTUNE)\n",
        "    return ds\n",
        "\n",
        "train_ds = prepare_for_training(train_ds)\n",
        "val_ds = prepare_for_training(val_ds)"
      ],
      "metadata": {
        "id": "0WXjMyAO3hrd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###5. 데이터 시각화"
      ],
      "metadata": {
        "id": "YDKfHoxwyARx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* 이미지 배치 입력 --> 여러장의 이미지 출력하기"
      ],
      "metadata": {
        "id": "r3A_qjI35PwQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def show_batch(image_batch, label_batch):\n",
        "    plt.figure(figsize=(10,10))\n",
        "    for n in range(BATCH_SIZE):\n",
        "        ax = plt.subplot(4,math.ceil(BATCH_SIZE/4),n+1)\n",
        "        plt.imshow(image_batch[n])\n",
        "        if label_batch[n]:\n",
        "            plt.title(\"PNEUMONIA\")\n",
        "        else:\n",
        "            plt.title(\"NORMAL\")\n",
        "        plt.axis(\"off\")"
      ],
      "metadata": {
        "id": "S1oDqcLT4SAU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image_batch, label_batch = next(iter(train_ds))"
      ],
      "metadata": {
        "id": "vghn86EE6Jjf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "show_batch(image_batch.numpy(), label_batch.numpy())"
      ],
      "metadata": {
        "id": "b-VnWoZa6Kjl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##3. 모델링, 하이퍼파라미터 튜닝"
      ],
      "metadata": {
        "id": "R3PMJk9crOLo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###1. CNN 모델링"
      ],
      "metadata": {
        "id": "-9j39FZtyGKl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "레이어 구성\n",
        "* 함수 처리로 모듈화"
      ],
      "metadata": {
        "id": "1vImqRhj4hIq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Convolution 레이어"
      ],
      "metadata": {
        "id": "1cYQyNQM4jIe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def conv_block(filters):\n",
        "    block = tf.keras.Sequential([\n",
        "        tf.keras.layers.SeparableConv2D(filters, 3, activation='relu', padding='same'),\n",
        "        tf.keras.layers.SeparableConv2D(filters, 3, activation='relu', padding='same'),\n",
        "        tf.keras.layers.BatchNormalization(),\n",
        "        tf.keras.layers.MaxPool2D()\n",
        "    ])\n",
        "\n",
        "    return block"
      ],
      "metadata": {
        "id": "N8XVRAPW4XTP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dense 레이어"
      ],
      "metadata": {
        "id": "Va2rqsZf4khA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def dense_block(units, dropout_rate):\n",
        "    block = tf.keras.Sequential([\n",
        "        tf.keras.layers.Dense(units, activation='relu'),\n",
        "        tf.keras.layers.BatchNormalization(),\n",
        "        tf.keras.layers.Dropout(dropout_rate)\n",
        "    ])\n",
        "\n",
        "    return block"
      ],
      "metadata": {
        "id": "e4ZAFucG4Zpv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* 두 가지 일반화성능 향상 기법 적용\n",
        "  * Batch Normalization : 배치 단위별 데이터 분포 정규화\n",
        "  * DropOut\n",
        "\n",
        "(동시에 사용하기로 함)"
      ],
      "metadata": {
        "id": "QR9My-BX4usz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "모델 전체구성 역시 함수 처리"
      ],
      "metadata": {
        "id": "uUVQzbQ77b0n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def build_model():\n",
        "    model = tf.keras.Sequential([\n",
        "        tf.keras.Input(shape=(IMAGE_SIZE[0], IMAGE_SIZE[1], 3)),\n",
        "\n",
        "        tf.keras.layers.Conv2D(16, 3, activation='relu', padding='same'),\n",
        "        tf.keras.layers.Conv2D(16, 3, activation='relu', padding='same'),\n",
        "        tf.keras.layers.MaxPool2D(),\n",
        "\n",
        "        conv_block(32),\n",
        "        conv_block(64),\n",
        "\n",
        "        conv_block(128),\n",
        "        tf.keras.layers.Dropout(0.2),\n",
        "\n",
        "        conv_block(256),\n",
        "        tf.keras.layers.Dropout(0.2),\n",
        "\n",
        "        tf.keras.layers.Flatten(),\n",
        "        dense_block(512, 0.7),\n",
        "        dense_block(128, 0.5),\n",
        "        dense_block(64, 0.3),\n",
        "\n",
        "        tf.keras.layers.Dense(1, activation='sigmoid')\n",
        "    ])\n",
        "\n",
        "    return model"
      ],
      "metadata": {
        "id": "X01WG2hz5Al4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###2. 데이터 불균형imbalance 처리"
      ],
      "metadata": {
        "id": "WwoJ0LGcyK_N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Weight balancing 기법을 사용한 불균형 처리\n",
        "\n",
        "(설명 출처 : 아이펠)\n",
        "* weight balancing: training set의 각 데이터에서 loss를 계산할 때 특정 클래스의 데이터에 더 큰 loss 값을 갖도록 가중치를 부여\n",
        "* Keras는 model.fit()을 호출할 때 파라미터로 넘기는 class_weight 에 이러한 클래스별 가중치를 세팅할 수 있도록 지원함"
      ],
      "metadata": {
        "id": "Mv5BwJSC9TO1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "weight_for_0 = (1 / COUNT_NORMAL)*(TRAIN_IMG_COUNT)/2.0\n",
        "weight_for_1 = (1 / COUNT_PNEUMONIA)*(TRAIN_IMG_COUNT)/2.0\n",
        "\n",
        "class_weight = {0: weight_for_0, 1: weight_for_1}\n",
        "\n",
        "print('Weight for NORMAL: {:.2f}'.format(weight_for_0))\n",
        "print('Weight for PNEUMONIA: {:.2f}'.format(weight_for_1))"
      ],
      "metadata": {
        "id": "4D-NV8fx5Imn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* 음성 이미지가 훨씬 적으므로 음성 이미지에 더 큰 가중치 부여"
      ],
      "metadata": {
        "id": "Ce01BZGD8cDE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###3. 모델 훈련"
      ],
      "metadata": {
        "id": "cjUU9EAzyNlW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "메트릭:\n",
        "* 정확도 (불균형이 있으므로 precision 및 recall로 더 정밀히 확인하기)\n",
        "* 이진분류이므로 binary_crossentropy\n",
        "* binary_crossentropy 비선형 손실함수를 사용하며 데이터가 불균형하므로, adam 옵티마이저 채택"
      ],
      "metadata": {
        "id": "yDPAmFM692EA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with tf.device('/GPU:0'):\n",
        "    model = build_model()\n",
        "\n",
        "    METRICS = [\n",
        "        'accuracy',\n",
        "        tf.keras.metrics.Precision(name='precision'),\n",
        "        tf.keras.metrics.Recall(name='recall')\n",
        "    ]\n",
        "\n",
        "    model.compile(\n",
        "        optimizer='adam',\n",
        "        loss='binary_crossentropy',\n",
        "        metrics=METRICS\n",
        "    )"
      ],
      "metadata": {
        "id": "etmM3tiF92f2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "outputId": "5c7a44ce-1378-46fa-c1c0-b1f74ef18c4e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'tf' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-31c12d34dc7b>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/GPU:0'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuild_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     METRICS = [\n\u001b[1;32m      5\u001b[0m         \u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'tf' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with tf.device('/GPU:0'):\n",
        "    history = model.fit(\n",
        "        train_ds,\n",
        "        steps_per_epoch=TRAIN_IMG_COUNT // BATCH_SIZE,\n",
        "        epochs=EPOCHS,\n",
        "        validation_data=val_ds,\n",
        "        validation_steps=VAL_IMG_COUNT // BATCH_SIZE,\n",
        "        class_weight=class_weight,\n",
        "    )"
      ],
      "metadata": {
        "id": "x4Kq24Pw9_dC",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "outputId": "f8d6f950-bfc9-4707-bca8-07f4686654ce"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'tf' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-0ad6984bc7ed>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/GPU:0'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     history = model.fit(\n\u001b[1;32m      3\u001b[0m         \u001b[0mtrain_ds\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTRAIN_IMG_COUNT\u001b[0m \u001b[0;34m//\u001b[0m \u001b[0mBATCH_SIZE\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mEPOCHS\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'tf' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###4. 훈련 결과 확인"
      ],
      "metadata": {
        "id": "i4S5BTW1yZur"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Epochs 마다 모델의\n",
        "* precision\n",
        "* recall\n",
        "* accuracy\n",
        "* loss\n",
        "\n",
        "가 어떻게 변했을까?"
      ],
      "metadata": {
        "id": "qg9FQ4UO-Pzx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fig, ax = plt.subplots(1, 4, figsize=(20, 3))\n",
        "ax = ax.ravel()\n",
        "\n",
        "for i, met in enumerate(['precision', 'recall', 'accuracy', 'loss']):\n",
        "    ax[i].plot(history.history[met])\n",
        "    ax[i].plot(history.history['val_' + met])\n",
        "    ax[i].set_title('Model {}'.format(met))\n",
        "    ax[i].set_xlabel('epochs')\n",
        "    ax[i].set_ylabel(met)\n",
        "    ax[i].legend(['train', 'val'])"
      ],
      "metadata": {
        "id": "840Hjo_C-Gyl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "모델 평가\n",
        "\n",
        "위와 동일한 내용을 출력한다.\n",
        "* loss\n",
        "* accuracy\n",
        "* precision\n",
        "* recall"
      ],
      "metadata": {
        "id": "89TMidnA-aEL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "loss, accuracy, precision, recall = model.evaluate(test_ds)\n",
        "print(f'Loss: {loss},\\nAccuracy: {accuracy},\\nPrecision: {precision},\\nRecall: {recall}')"
      ],
      "metadata": {
        "id": "o3WidM6U-KTT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##4. 성능 개선"
      ],
      "metadata": {
        "id": "AxledpOcybYK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Residual Network 구성"
      ],
      "metadata": {
        "id": "91pWE77-AVvW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "YoJJOg1ST83F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# class ResNetBlock(Layer):\n",
        "#   def __init__(self, filters, strides=1):\n",
        "#     super(self).__init__()\n",
        "\n",
        "#     first_padding = 'same'\n",
        "#     if strides != 1:\n",
        "#       first_padding = 'valid'\n",
        "\n",
        "#   self.conv_sequence = Sequential([\n",
        "#       Conv2D(filters, 3, first_stride, padding=first_padding),\n",
        "#       BatchNormalization(),\n",
        "#       Activation('relu'),\n",
        "\n",
        "#       Conv2D(filters, 3, 1, padding='same'),\n",
        "#       BatchNormalization(),\n",
        "#       Activation('relu')\n",
        "#   ])\n",
        "\n",
        "#   def call(self, inputs):\n",
        "#     x = self.conv_sequence(inputs)\n",
        "\n",
        "#     # skip connection\n",
        "#     if x.shape == inputs.shape:\n",
        "#       x += inputs\n",
        "\n",
        "#     return x"
      ],
      "metadata": {
        "id": "BJk-QOa6UMqu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# class ResNet(Model):\n",
        "#   def __init__(self):\n",
        "#     super(ResNet, self).__init__()\n",
        "\n",
        "#     self.conv_1 = tf.keras.layers.Conv2D(16, 3, activation='relu', padding='same')\n",
        "\n",
        "#     self.resnet_chains = Sequential([ResNetBlock(64), ResNetBlock(64)] +\n",
        "#                                      [ResNetBlock(128, 2), ResNetBlock(128)] +\n",
        "#                                      [ResNetBlock(256, 2), ResNetBlock(256)] +\n",
        "#                                      [ResNetBlock(512, 2), ResNetBlock(512)])\n",
        "\n",
        "#     self.out = Sequential(GlobalAveragePooling2D(), Dense(1, activation='sigmoid'))\n",
        "\n",
        "#   def call(self, x):\n",
        "#     x = self.conv_1(x)\n",
        "#     x = self.resnet_chains(x)\n",
        "#     x = self.out(x)\n",
        "#     return x"
      ],
      "metadata": {
        "id": "lYRe1TLDAUKD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = ResNet()"
      ],
      "metadata": {
        "id": "HRqFnk2zVd7g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.build(input_shape=(None, 224, 224, 3))"
      ],
      "metadata": {
        "id": "JffMlfEJVk8_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_model(model, show_shapes=True)"
      ],
      "metadata": {
        "id": "Y092NhWTV2Rk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "학습률 재설정"
      ],
      "metadata": {
        "id": "pqiSm5_2Bbxu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "####Data Augmentation"
      ],
      "metadata": {
        "id": "TqGvLbVZyjTc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "GAN을 이용한 Data Augmentation"
      ],
      "metadata": {
        "id": "eFMJNUnbymI9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "좌우반전 적용"
      ],
      "metadata": {
        "id": "TvG7i3NTroJY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def augment(image,label):\n",
        "    image = tf.image.random_flip_left_right(image)  # 랜덤하게 좌우를 반전합니다.\n",
        "    return image,label\n",
        "\n",
        "def prepare_for_training(ds, shuffle_buffer_size=1000):\n",
        "    # augment 적용 부분이 배치처리 함수에 추가되었습니다.\n",
        "    ds = ds.map(\n",
        "            augment,       # augment 함수 적용\n",
        "            num_parallel_calls=2\n",
        "        )\n",
        "    ds = ds.shuffle(buffer_size=shuffle_buffer_size)\n",
        "    ds = ds.repeat()\n",
        "    ds = ds.batch(BATCH_SIZE)\n",
        "    ds = ds.prefetch(buffer_size=AUTOTUNE)\n",
        "\n",
        "    return ds\n",
        "\n",
        "train_ds = prepare_for_training(train_ds)\n",
        "val_ds = prepare_for_training(val_ds)"
      ],
      "metadata": {
        "id": "zUbY-WUdrlH_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###훈련 결과 확인 (재)"
      ],
      "metadata": {
        "id": "SHKjUk_E-jyk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fig, ax = plt.subplots(1, 4, figsize=(20, 3))\n",
        "ax = ax.ravel()\n",
        "\n",
        "for i, met in enumerate(['precision', 'recall', 'accuracy', 'loss']):\n",
        "    ax[i].plot(history.history[met])\n",
        "    ax[i].plot(history.history['val_' + met])\n",
        "    ax[i].set_title('Model {}'.format(met))\n",
        "    ax[i].set_xlabel('epochs')\n",
        "    ax[i].set_ylabel(met)\n",
        "    ax[i].legend(['train', 'val'])"
      ],
      "metadata": {
        "id": "Fq0cgV8m_52t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##5. 예측 및 평가"
      ],
      "metadata": {
        "id": "mmBMzTncAF_K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "loss, acc, prec, rec = model.evaluate(test_ds)"
      ],
      "metadata": {
        "id": "-ogUd4lmARF9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "회고\n",
        "\n",
        "시간이 충분히 주어졌는데도 그 시간을 충분히 사용하지 못했다. 팀프로젝트에 차질 없도록 반드시 따라잡겠다."
      ],
      "metadata": {
        "id": "DWjlYwHTyQq6"
      }
    }
  ]
}